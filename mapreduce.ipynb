{"cells":[{"cell_type":"markdown","source":["# IST 718: Big Data Analytics\n\n- Professor: Daniel Acuna <deacuna@syr.edu>\n\n## General instructions:\n\n- You are welcome to discuss the problems with your classmates but __you are not allowed to copy any part of your answers either from your classmates or from the internet__\n- You can put the homework files anywhere you want in your http://notebook.acuna.io workspace but _do not change_ the file names. The TAs and the professor use these names to grade your homework.\n- Remove or comment out code that contains `raise NotImplementedError`. This is mainly to make the `assert` statement fail if nothing is submitted.\n- The tests shown in some cells (i.e., `assert` and `np.testing.` statements) are used to grade your answers. **However, the professor and TAs will use __additional__ test for your answer. Think about cases where your code should run even if it passess all the tests you see.**\n- Before downloading and submitting your work through Blackboard, remember to save and press `Validate` (or go to \n`Kernel`$\\rightarrow$`Restart and Run All`). \n- Good luck!"],"metadata":{}},{"cell_type":"code","source":["# this code creates the spark session\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\nsc = spark.sparkContext\nimport numpy as np"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["# Part 1: Map-Reduce: Gradient descent\n\nThroughout this assignment, you should use vanilla Python and not Numpy."],"metadata":{}},{"cell_type":"markdown","source":["Some statistical models $f(x)$ are learned by optimizing a loss function $L(\\Theta)$ that depends on a set of parameters $\\Theta$. There are several ways of finding the optimal $\\Theta$ for the loss function, one of which is to iteratively update following the gradient:\n\n$$\n\\nabla L = \n\\begin{pmatrix} \n    \\frac{\\partial L}{\\partial \\theta_0}\\\\ \n    \\frac{\\partial L}{\\partial \\theta_1} \\\\ \n    \\vdots\\\\ \n    \\frac{\\partial L}{\\partial \\theta_p}\n\\end{pmatrix}\n$$\n\nTo then, compute the update\n$$\\Theta^{t+1} = \\Theta^t - \\eta \\nabla L$$\n\nBecause we assume independence between data points, the gradient becomes a summation:\n\n$$\\nabla L = \\sum_{i=1}^{n} \\nabla L_i$$\nwhere $L_i$ is the loss function for the $i$-th data point.\n\nTake as example, the statistical model $f(x) = b_0 + b_1 x$ and loss function $L(\\Theta) = (f(x) - y)^2$. If we have a set of three datapoints $D=\\{ (x=1,y=2), (x=-2, y=-1), (x=4, y = 3)\\}$\n\nThen the loss function for each of them is\n$L_1 = \\left(b_{0} + b_{1} - 2\\right)^{2}$, \n$L_2 = \\left(b_{0} - 2 b_{1} + 1\\right)^{2}$, and\n$L_3 = \\left(b_{0} + 4 b_{1} - 3\\right)^{2}$\n\nwith \n$$\\nabla L_i = \\left[\\begin{matrix}2 b_{0} + 2 b_{1} x_i - 2 y_i\\\\2 x_i \\left(b_{0} + b_{1} x_i - y_i\\right)\\end{matrix}\\right]$$\n\nif we start with a solution $b_0 = 0, b_1 = 1$, then the gradients are:\n\n$$\\nabla L_1 = \\left[\\begin{matrix}-2\\\\-2\\end{matrix}\\right]$$\n$$\\nabla L_2 = \\left[\\begin{matrix}-2\\\\4\\end{matrix}\\right]$$\n$$\\nabla L_3 = \\left[\\begin{matrix}2\\\\8\\end{matrix}\\right]$$\n\nwhich after accumulation would yield\n$$\\nabla L = \\left[\\begin{matrix}-2\\\\10\\end{matrix}\\right]$$"],"metadata":{}},{"cell_type":"markdown","source":["## Question 1 (5 pts)\n\nCreate a function `f_linear(b, x)` that receives the parameters `b` and one data point `x` as lists and return the prediction for that data point. Assume that the first element of `b` is the intercept."],"metadata":{}},{"cell_type":"code","source":["# define below the function `f_linear` which performs a linear prediction based on parameters as data point\ndef f_linear(b, x):\n    z = b[0]\n    for i in range(len(x)):\n        z = z + b[i+1]*x[i]\n    return(z)\n    "],"metadata":{"deletable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-e260b0944cc2cafb","locked":false,"solution":true,"checksum":"1ee003cc0679b4304ff2fa404558cd6f","grade":false}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# for the example above, if we assume b = [0, 1], and the first data point x = [1], y = 2\nf_linear([0, 1], [1])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[46]: 1</div>"]}}],"execution_count":7},{"cell_type":"code","source":["# test (5 pts)\nassert f_linear([1, 1, 2, 3], [2, 1, 3]) == 14\nassert f_linear([1], []) == 1\nassert f_linear([0, 1, 0, 1, 0, 1], [0, 10, 10, 10 , 10]) == 20"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-e12a1ead7bf3835d","locked":true,"solution":false,"points":5,"checksum":"4cdbdeeae72fba84e40d267674140347","grade":true}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["## Question 2 (5 pts)\nDefine the function `L(y_pred, y)` that receives a prediction `y_pred` and the actual value `y` and returns the squared error between them."],"metadata":{}},{"cell_type":"code","source":["def L(y_pred, y):\n  z= (y - y_pred)**2\n  return z\n"],"metadata":{"deletable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-b624ab75860c6e6e","locked":false,"solution":true,"checksum":"7892a587f9bd66149dc1402292150369","grade":false}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["# there should be not error here\nL(1, 1)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[55]: 0</div>"]}}],"execution_count":11},{"cell_type":"code","source":["# 2^2 error\nL(0, 2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[56]: 4</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# (5 pts)\nassert L(1, 1) == 0\nassert L(0, 4) == 16"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-335fe2ab491bce32","locked":true,"solution":false,"points":5,"checksum":"7857ffedf06e01569d1fa76de2392278","grade":true}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"markdown","source":["## Question 3 (10 pts)\nCreate a function `gf_linear(f, b, x, y)` which returns the gradient of the linear function `f` with parameter `b` with respect to the squared loss function, evaluated at `x` and the actual outcome `y`. This function should return a vector with each element $j$ corresponding to the gradient with respect $b_j$, with $j = \\{0, 1, \\dots, p\\}$."],"metadata":{}},{"cell_type":"code","source":["def gf_linear(f, b, x, y):\n    f = f_linear(b,x)\n    Data_point = []\n    if len(x) == 0:\n        a = 2*(f - y)\n        Data_point.append(a)\n     \n    else:\n      a = 2*(f-y)\n      Data_point.append(a)\n      Data_point2 =[]\n      for i in range(len(x)):\n        Data_point2 = 2*x[i]*(f-y)\n        Data_point.append(Data_point2)\n    return Data_point"],"metadata":{"deletable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-2d3493c9766da5c1","locked":false,"solution":true,"checksum":"f7329f34aa05e0b8ef30faedf9750a13","grade":false}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["# for the example above and first data point\nx = [1]\ny = 2\nb = [0, 1]\ngf_linear(f_linear, b, x, y)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[90]: [-2, -2]</div>"]}}],"execution_count":16},{"cell_type":"code","source":["# for the example above and second data point\nx = [-2]\ny = -1\nb = [0, 1]\ngf_linear(f_linear, b, x, y)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[91]: [-2, 4]</div>"]}}],"execution_count":17},{"cell_type":"code","source":["## (10 pts)\nnp.testing.assert_array_equal(gf_linear(f_linear, [0, 1], [1], 2), [-2, -2])\nnp.testing.assert_array_equal(gf_linear(f_linear, [0, 1], [-2], -1), [-2, 4])\nnp.testing.assert_array_equal(gf_linear(f_linear, [1], [], 0), [2])"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-bc73ed6d8073de74","locked":true,"solution":false,"points":10,"checksum":"bcc6f859ba2c7ba8deb2a7232799d986","grade":true}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"markdown","source":["## Question 4 (15 pts)\n\nDevelop a map-reduce job that produces a value so that the first element of the value is the mean loss function across all the data. You might use other pieces of information as part of the value to create your computation.\n\nYou will implement your map function as `map_mse(f, b, L, xy)` where `f` is the function `b` are the parameters of the function `L` is the loss function and `xy` is the data. Assume that the data will come as an RDD where each element is of the format:\n\n`[x, y]` where `x` is a list and `y` is a scalar.\n\nSince the key does not matter for this map reduce job, just put a constant of your choice."],"metadata":{}},{"cell_type":"code","source":["# data\nrdd_data = sc.parallelize([\n    [[1, 2], 3],\n    [[3, 1], 4],\n    [[-1, 1.5], 0],\n    [[-9, 3], 0]\n])"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-481c573523c2b098","locked":true,"solution":false,"checksum":"9783bb5e9503f2ef935c7cb83c2fc43b","grade":false}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"code","source":["\n# create function `map_mse` below\ndef map_mse(f, b, L, xy):\n    f = f_linear(b,xy[0])\n    L= L(f,xy[1])\n    return [1,[L,1]]"],"metadata":{"deletable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-f87dee01323b2e82","locked":false,"solution":true,"checksum":"bb5b73b9485caf4962b2cef35a565c10","grade":false}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["You should apply the map function in the following way:\n\n```python\n# for an example set of `b = [0, 0, 0]`\nrdd_data.map(lambda x: map_generator(f_linear, [0, 0, 0], L, x))\n```"],"metadata":{}},{"cell_type":"code","source":["# try it here\nrdd_data.map(lambda x: map_mse(f_linear, [0, 0, 0], L, x)).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[97]: [[1, [9, 1]], [1, [16, 1]], [1, [0.0, 1]], [1, [0, 1]]]</div>"]}}],"execution_count":23},{"cell_type":"code","source":["# (10 pts)\nassert rdd_data.map(lambda x: map_mse(f_linear, [0, 0, 0], L, x)).count() == 4\nassert rdd_data.map(lambda x: map_mse(f_linear, [0, 0, 0], L, x)).map(lambda x: len(x)).\\\n    distinct().\\\n    first() == 2\n\nassert rdd_data.map(lambda x: map_mse(f_linear, [0, 0, 0], L, x)).count() == 4\n# the first element should be a number\nassert isinstance((rdd_data.map(lambda x: map_mse(f_linear, [0, 0, 0], L, x)).first()[1][0]), \n                  (int, float, complex))\n# try with other initializations\nassert isinstance((rdd_data.map(lambda x: map_mse(f_linear, [1, 2, 3], L, x)).first()[1][0]), \n                  (int, float, complex))"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-449c2d0c5f77a1af","locked":true,"solution":false,"points":10,"checksum":"dbda664de2ce3dee744024f1bf661087","grade":true}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["You will now create a reduce job that receives two values of a previous reduce (or map) and merge them appropriately. Remember that at the end of the reduce job, the first element of the value should be the mean squared error. Create the function `reduce_mse(v1, v2)` below."],"metadata":{}},{"cell_type":"code","source":["# create function `reduce_mse` below\ndef reduce_mse(v1, v2):\n    a1,n1 = v1\n    a2,n2 = v2\n    return[(a1*n1+a2*n2)/(n1+n2),n1+n2]\n    raise NotImplementedError()"],"metadata":{"deletable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-664ff0abbe2fe932","locked":false,"solution":true,"checksum":"d4c7b7e49c6fcf2dbf3b3d525ef5e86d","grade":false}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"code","source":["# the following function call should return the mean squared error\nrdd_data.\\\n    map(lambda x: map_mse(f_linear, [0, 0, 0], L, x)).\\\n    reduceByKey(reduce_mse).first()[1][0]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[100]: 6.25</div>"]}}],"execution_count":27},{"cell_type":"code","source":["# the following function call should return the mean squared error\nrdd_data.\\\n    map(lambda x: map_mse(f_linear, [2, 2, 3], L, x)).\\\n    reduceByKey(reduce_mse).first()[1][0]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[101]: 41.8125</div>"]}}],"execution_count":28},{"cell_type":"code","source":["# (5 pts)\nassert rdd_data.\\\n    map(lambda x: map_mse(f_linear, [0, 0, 0], L, x)).\\\n    reduceByKey(reduce_mse).first()[1][0] == 6.25\n\nassert rdd_data.\\\n    map(lambda x: map_mse(f_linear, [2, 0, 0], L, x)).\\\n    reduceByKey(reduce_mse).first()[1][0] == 3.25\n\nassert rdd_data.\\\n    map(lambda x: map_mse(f_linear, [2, 2, 3], L, x)).\\\n    reduceByKey(reduce_mse).first()[1][0] == 41.8125"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-39ff3270d4901c44","locked":true,"solution":false,"points":5,"checksum":"ddfe12639adf21efa38a1554e59cdb37","grade":true}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["## Question 5 (10 pts)\n\nIn this question, you will compute the cumulative gradient of a model on the data. You will define a map function `map_gradient(f, gf, b, xy)` that would receive a function `f`, its gradient `gf`, its parameters `b`, and a data point `xy = [x, y]`. Also you will define a function `reduce_gradient(v1, v2)` that combines the two values appropriately. In the map function, you probably do not need to keep extra values beyond the actual gradient."],"metadata":{}},{"cell_type":"code","source":["# define the function `map_gradient` below\ndef map_gradient(f, gf, b, xy):\n    gf = gf_linear(f,b,xy[0],xy[1])\n    print(gf)\n    return [1,gf]\n    raise NotImplementedError()"],"metadata":{"deletable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-f6fa0087a0af6012","locked":false,"solution":true,"checksum":"3b5464a0f7f432697ee6d51651071c13","grade":false}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["# (5 pts)\nassert len(rdd_data.map(lambda xy: map_gradient(f_linear, gf_linear, [0, 0, 0], xy)[1]).first()) == 3"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-85e6b947e7eab1ca","locked":true,"solution":false,"points":5,"checksum":"2783391c2092700ae7af8efe7da67aec","grade":true}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"code","source":["# define the function `reduce_gradient` below\ndef reduce_gradient(v1, v2):\n    reduce_grad=[]\n    for i in range(len(v1)):\n        reduce_grad.append(v1[i]+v2[i])\n    return(reduce_grad)\n    raise NotImplementedError()"],"metadata":{"deletable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-d3a5661b89fd6eec","locked":false,"solution":true,"checksum":"ba1a1e364bf1c1610dba927c27ce4ca8","grade":false}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":33},{"cell_type":"code","source":["rdd_data.map(lambda xy: map_gradient(f_linear, gf_linear, [0, 0, 0], xy))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[106]: PythonRDD[563] at RDD at PythonRDD.scala:59</div>"]}}],"execution_count":34},{"cell_type":"code","source":["# (5 pts)\nnp.testing.assert_array_equal(\n    rdd_data.map(lambda xy: map_gradient(f_linear, gf_linear, [0, 0, 0], xy)).\\\n    reduceByKey(reduce_gradient).first()[1],\n    [-14.0, -30.0, -20.0])\n\nnp.testing.assert_array_equal(\n    rdd_data.map(lambda xy: map_gradient(f_linear, gf_linear, [0, 0, 0], xy)).\\\n    reduceByKey(reduce_gradient).first()[1],\n    [-14.0, -30.0, -20.0])"],"metadata":{"deletable":false,"editable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-7f50da09ee10e7d1","locked":true,"solution":false,"points":5,"checksum":"ed8453696d68f53bc7e3d30156f7f8da","grade":true}},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["if all your answers are correct, then we can run an optimization below, and the MSE should decrease with each iteration"],"metadata":{}},{"cell_type":"code","source":["b = [0, 0, 0]\nlearning_rate = 0.07\nprint(\"Initial solution: \\t\", b)\nfor _ in range(10):\n    print(\"New iteration\")\n    print(\"=============\")\n    gradient = rdd_data.map(lambda xy: map_gradient(f_linear, gf_linear, b, xy)).\\\n        reduceByKey(reduce_gradient).first()[1]\n    b = [b0 - learning_rate*g0 for b0, g0 in zip(b, gradient)]\n    print(\"Current solution: \\t\", b)\n    mse = rdd_data.\\\n        map(lambda x: map_mse(f_linear, b, L, x)).\\\n        reduceByKey(reduce_mse).first()[1][0]\n    print(\"Current MSE: \\t\\t\", mse)\n    \n    "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Initial solution: \t [0, 0, 0]\nNew iteration\n=============\nCurrent solution: \t [0.9800000000000001, 2.1, 1.4000000000000001]\nCurrent MSE: \t\t 54.84890000000002\nNew iteration\n=============\nCurrent solution: \t [1.7052, -17.4188, 5.495000000000002]\nCurrent MSE: \t\t 8456.470431502501\nNew iteration\n=============\nCurrent solution: \t [-18.671254000000005, 228.54626200000004, -64.70443700000001]\nCurrent MSE: \t\t 1408496.6794462374\nNew iteration\n=============\nCurrent solution: \t [252.68316717000008, -2941.5910436500008, 855.4201758550003]\nCurrent MSE: \t\t 234678412.15249926\nNew iteration\n=============\nCurrent solution: \t [-3256.967067758951, 37974.78783754776, -11032.412583352128]\nCurrent MSE: \t\t 39101294605.30528\nNew iteration\n=============\nCurrent solution: \t [42050.76948624592, -490170.8692462134, 142424.59345045302]\nCurrent MSE: \t\t 6514920725946.685\nNew iteration\n=============\nCurrent solution: \t [-542786.0347158468, 6327131.585465453, -1838405.424429928]\nCurrent MSE: \t\t 1085493268072228.4\nNew iteration\n=============\nCurrent solution: \t [7006291.352167432, -81670615.25086537, 23730156.56878114]\nCurrent MSE: \t\t 1.8086108559043782e+17\nNew iteration\n=============\nCurrent solution: \t [-90437212.03299345, 1054204411.1273915, -306308878.3203189]\nCurrent MSE: \t\t 3.0134440482568835e+19\nNew iteration\n=============\nCurrent solution: \t [1167363655.2688265, -13607671869.874975, 3953835406.5021677]\nCurrent MSE: \t\t 5.02089490524154e+21\n</div>"]}}],"execution_count":37},{"cell_type":"markdown","source":["**(5 pts)** In the code, above, play with the value of `learning_rate` less than 1.0 until the optimizer diverges (the loss function goes down and then goes *up*). What is this learning rate?"],"metadata":{}},{"cell_type":"code","source":["#To reach the optimal solution we use a rate at which we adjust our optimal soltion during each process. "],"metadata":{"deletable":false,"nbgrader":{"schema_version":1,"grade_id":"cell-49ee8798a623ecdf","locked":false,"solution":true,"points":5,"checksum":"cc837820a5a204f6d39c8fd064139e4b","grade":true}},"outputs":[],"execution_count":39},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":40}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.4","nbconvert_exporter":"python","file_extension":".py"},"name":"mapreduce","notebookId":2655253198705040},"nbformat":4,"nbformat_minor":0}
